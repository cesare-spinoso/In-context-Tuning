{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9901298522949219"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nvidia_smi\n",
    "\n",
    "def get_gpu_allocated_mem():\n",
    "    nvidia_smi.nvmlInit()\n",
    "    deviceCount = nvidia_smi.nvmlDeviceGetCount()\n",
    "    handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
    "    return info.free/info.total\n",
    "\n",
    "get_gpu_allocated_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "from typing import NamedTuple, OrderedDict\n",
    "import numpy as np\n",
    "import torch\n",
    "from ict_2 import ICT\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from copy import deepcopy\n",
    "import os\n",
    "from data_loader import DataLoader\n",
    "import random\n",
    "\n",
    "current_dir = Path(os.path.join(os.path.abspath(\".\")))\n",
    "\n",
    "cv_split = pkl.load(\n",
    "    open(current_dir / \"data_biclfs\" / \"cross_validation_splits.pkl\", \"rb\")\n",
    ")\n",
    "training_data = pkl.load(\n",
    "    open(current_dir / \"data_biclfs\" / \"training_data_templated.pkl\", \"rb\")\n",
    ")\n",
    "verbalizers = [\"no\", \"yes\"]\n",
    "\n",
    "fold_0 = cv_split[0]\n",
    "\n",
    "task2verbalizers = {task: verbalizers for task in fold_0[\"train\"]}\n",
    "task2template_examples = {task: training_data[task] for task in fold_0[\"train\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2-medium\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a00575e97ff84705a7bce6b0fed59bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preparing training examples.:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 1024). Running this sequence through the model will result in indexing errors\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1033. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1045. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1039. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1103. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1148. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1052. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1026. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1096. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1034. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1111. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1049. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1074. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1146. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1043. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1100. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1028. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1072. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1145. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1037. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1044. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1084. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1063. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1050. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1098. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1040. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1029. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1088. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1218. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1075. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1031. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1066. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1027. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1048. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1032. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1064. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1107. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1047. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1090. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1061. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1071. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1041. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1083. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1065. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1155. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1109. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1060. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1087. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1178. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1139. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1059. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1025. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1175. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1151. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1092. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1068. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n",
      "/home/mila/c/cesare.spinoso/In-context-Tuning/src/data_loader.py:175: UserWarning: MODEL LENGTH EXCEEDED. Length of input text is 1143. This exceeds the model's max length of 1024.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Training data creation\n",
    "bsz = 8\n",
    "# Create dataloader\n",
    "data_loader = DataLoader(\n",
    "    tokenizer=tokenizer,\n",
    "    task_format=\"clm\",\n",
    "    task2verbalizers=task2verbalizers,\n",
    "    example_delimiter=\" \",\n",
    "    device=\"cuda\",\n",
    ")\n",
    "# Prepare the training examples\n",
    "epoch_train_examples = []  # List of training batches\n",
    "for task in tqdm(task2template_examples, desc=\"Preparing training examples.\"):\n",
    "    # Loop by task so batches only contain examples of the same task\n",
    "    training_examples = []\n",
    "    examples = task2template_examples[task]\n",
    "    for query_example in examples:\n",
    "        # Remove the random selection of templates\n",
    "        input_text = data_loader.prepare_input(\n",
    "            task,\n",
    "            query_example,\n",
    "            examples,\n",
    "            5,\n",
    "            True,\n",
    "            template=None,\n",
    "        )\n",
    "        # NOTE: Current implementation filters out completely the\n",
    "        # examples that exceed model's maximum token length, will\n",
    "        # probably need to change this so that we truncate rather than\n",
    "        # filter out the example entirely\n",
    "        convert_label_to_string = lambda x: \"no\" if x == 0 else \"yes\"\n",
    "        if (\n",
    "            len(tokenizer(input_text)[\"input_ids\"]) <= tokenizer.model_max_length\n",
    "        ):\n",
    "            training_examples.append(\n",
    "                (task, input_text, convert_label_to_string(query_example[\"<label>\"]))\n",
    "            )\n",
    "    # Divide model_examples into batches, so that each batch has all examples from the same task\n",
    "    # Shuffle within batch examples\n",
    "    random.shuffle(training_examples)\n",
    "    for idx in range(0, len(training_examples), bsz):\n",
    "        epoch_train_examples.append(training_examples[idx : idx + bsz])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('group3_2019SemEval5TweetEvalHate',\n",
       " '@user @user @user Expose the Corruption #DeclassifyFISA #MAGA #AmericaFirst #KAG #BuildThatWall  Is this tweet offensive towards women or immigrants? no #Buildthatwall #Deportthemall @user More Needless Deaths at the Hands of an Illegal Alien, and an Oregon Ballot Initiative  Is there hate speech towards women or immigrants in the tweet? yes @user OK BITCH WELL ILL LEFT SWIPE YOU AGAIN HOE BYEEEEE ‼️  Does the tweet contain hate speech towards women or immigrants? ',\n",
       " 'yes')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_train_examples[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2-medium\")\n",
    "model.to(\"cuda\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split weights in two groups, one with weight decay and the other not.\n",
    "no_decay = [\"bias\", \"layer_norm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "545b99022d96413baf76ea7bd06cd085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9081672668457031\n",
      "0.8373664855957031\n",
      "0.7695198059082031\n",
      "0.7695198059082031\n",
      "0.7668830871582031\n",
      "0.7668830871582031\n",
      "0.7668830871582031\n",
      "0.33883132934570315\n",
      "0.3018684387207031\n",
      "0.3018684387207031\n",
      "0.3018684387207031\n",
      "0.3018684387207031\n",
      "0.3018684387207031\n",
      "0.3018684387207031\n",
      "0.3018684387207031\n",
      "0.3018684387207031\n",
      "0.3018684387207031\n",
      "0.3018684387207031\n",
      "0.3018684387207031\n",
      "0.3018684387207031\n",
      "0.3018684387207031\n",
      "0.3018684387207031\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.28341140747070315\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.15216140747070311\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.07613601684570312\n",
      "0.018714141845703126\n",
      "0.018714141845703126\n",
      "0.018714141845703126\n",
      "0.34578933715820315\n",
      "0.34578933715820315\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3075569152832031\n",
      "0.3063850402832031\n",
      "0.3063850402832031\n",
      "0.3060920715332031\n",
      "0.3060920715332031\n",
      "0.3060920715332031\n",
      "0.3060920715332031\n",
      "0.3060920715332031\n",
      "0.3060920715332031\n",
      "0.3060920715332031\n",
      "0.3060920715332031\n",
      "0.30550613403320315\n",
      "0.30550613403320315\n"
     ]
    }
   ],
   "source": [
    "# small training loop\n",
    "for epoch in range(1):\n",
    "    for batch in tqdm(epoch_train_examples):\n",
    "        optimizer.zero_grad()\n",
    "        input_dict = tokenizer(\n",
    "            [example[1] for example in batch],\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\",).to(\"cuda\")\n",
    "        labels = torch.tensor(tokenizer.convert_tokens_to_ids([example[2] for example in batch]), dtype=torch.int64).to(\"cuda\")\n",
    "        outputs = model(**input_dict)\n",
    "        logits_last_token = outputs.logits[:, -1, :]\n",
    "        loss = cross_entropy(logits_last_token, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(get_gpu_allocated_mem())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ict",
   "language": "python",
   "name": "ict"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
