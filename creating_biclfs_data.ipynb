{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "import random\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import itertools\n",
    "cwd = os.getcwd()\n",
    "biclfs_paper_data = Path(cwd) / \"data_biclfs_paper\" / \"data\"\n",
    "biclfs_data_dir = Path(cwd) / \"data_biclfs\"\n",
    "training_dir = biclfs_paper_data / \"training_dicts\"\n",
    "testing_dir = biclfs_paper_data / \"testing_dicts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "task2training_data = {}\n",
    "task2testing_data = {}\n",
    "for filepath in training_dir.glob(\"*.pkl\"):\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        data = pkl.load(f)\n",
    "        task2training_data[filepath.stem] = data\n",
    "for filepath in testing_dir.glob(\"*.pkl\"):\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        data = pkl.load(f)\n",
    "        task2testing_data[filepath.stem] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_groups = [task.split(\"_\")[0] for task in task2training_data]\n",
    "test_groups = [task.split(\"_\")[0] for task in task2testing_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['group0', 'group1', 'group2', 'group3'],\n",
       "  ['group4', 'group5', 'group6', 'group7'],\n",
       "  ['group8',\n",
       "   'group9',\n",
       "   'group10',\n",
       "   'group11',\n",
       "   'group12',\n",
       "   'group13',\n",
       "   'group14',\n",
       "   'group15',\n",
       "   'group16',\n",
       "   'group17',\n",
       "   'group18',\n",
       "   'group19']],\n",
       " [['group0', 'group1', 'group2', 'group3'],\n",
       "  ['group4', 'group7'],\n",
       "  ['group8', 'group9', 'group10', 'group14', 'group18', 'group19']])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_split = [[0, 3], [4, 7], [8, 19]]\n",
    "cv_split = [[f\"group{x}\" for x in range(fold[0], fold[1] + 1)] for fold in cv_split]\n",
    "train_folds = []\n",
    "test_folds = []\n",
    "for fold in cv_split:\n",
    "    train_folds.append([])\n",
    "    test_folds.append([])\n",
    "    for group in fold:\n",
    "        if group in test_groups:\n",
    "            test_folds[-1].append(group)\n",
    "        if group in train_groups:\n",
    "            train_folds[-1].append(group)\n",
    "train_folds, test_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'train': ['group0', 'group1', 'group2', 'group3'],\n",
       "  'val': ['group4', 'group5', 'group6', 'group7'],\n",
       "  'test': ['group8',\n",
       "   'group9',\n",
       "   'group10',\n",
       "   'group11',\n",
       "   'group12',\n",
       "   'group13',\n",
       "   'group14',\n",
       "   'group15',\n",
       "   'group16',\n",
       "   'group17',\n",
       "   'group18',\n",
       "   'group19']},\n",
       " {'train': ['group4', 'group5', 'group6', 'group7'],\n",
       "  'val': ['group8',\n",
       "   'group9',\n",
       "   'group10',\n",
       "   'group11',\n",
       "   'group12',\n",
       "   'group13',\n",
       "   'group14',\n",
       "   'group15',\n",
       "   'group16',\n",
       "   'group17',\n",
       "   'group18',\n",
       "   'group19'],\n",
       "  'test': ['group0', 'group1', 'group2', 'group3']},\n",
       " {'train': ['group8',\n",
       "   'group9',\n",
       "   'group10',\n",
       "   'group11',\n",
       "   'group12',\n",
       "   'group13',\n",
       "   'group14',\n",
       "   'group15',\n",
       "   'group16',\n",
       "   'group17',\n",
       "   'group18',\n",
       "   'group19'],\n",
       "  'val': ['group0', 'group1', 'group2', 'group3'],\n",
       "  'test': ['group4', 'group5', 'group6', 'group7']}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to the format used in paper\n",
    "index_split = [[0, 1, 2], [1, 2, 0], [2, 0, 1]]\n",
    "random.shuffle(index_split)\n",
    "cv_split_ict = []\n",
    "for split in index_split:\n",
    "    cv_split_ict.append(\n",
    "        {\n",
    "            \"train\": train_folds[split[0]],\n",
    "            \"val\": train_folds[split[1]],\n",
    "            \"test\": train_folds[split[2]],\n",
    "        }\n",
    "    )\n",
    "cv_split_ict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with actual task names\n",
    "for i, split in enumerate(cv_split_ict):\n",
    "    cv_split_ict[i] = {\n",
    "        \"train\": [task for task in task2training_data if task.split(\"_\")[0] in split[\"train\"]],\n",
    "        \"val\": [task for task in task2testing_data if task.split(\"_\")[0] in split[\"val\"]],\n",
    "        \"test\": [task for task in task2testing_data if task.split(\"_\")[0] in split[\"test\"]],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_train = []\n",
    "for split in cv_split_ict:\n",
    "    check_train += split[\"train\"]\n",
    "assert sorted(check_train) == sorted(list(task2training_data.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_val = []\n",
    "check_test = []\n",
    "for split in cv_split_ict:\n",
    "    check_val += split[\"val\"]\n",
    "    check_test += split[\"test\"]\n",
    "assert sorted(check_val) == sorted(list(task2testing_data.keys()))\n",
    "assert sorted(check_test) == sorted(list(task2testing_data.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(biclfs_data_dir / \"cross_validation_splits.pkl\", \"wb\") as f:\n",
    "    pkl.dump(cv_split_ict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to the format used in paper (which I believe is incorrect)\n",
    "# The only difference is that the data from the training\n",
    "# fold will be separate from the one in the val and testing fold\n",
    "training_data = {\n",
    "    task: [{\"<input>\": example[\"c\"], \"<label>\": example[\"a\"]} for example in examples]\n",
    "    for task, examples in task2training_data.items()\n",
    "}\n",
    "training_templates = {\n",
    "    task: list(set([f\"<input> {example['q']} <label>\" for example in examples]))\n",
    "    for task, examples in task2training_data.items()       \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(biclfs_data_dir / \"training_data.pkl\", \"wb\") as f:\n",
    "    pkl.dump(training_data, f)\n",
    "with open(biclfs_data_dir / \"training_templates.pkl\", \"wb\") as f:\n",
    "    pkl.dump(training_templates, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The testing format is different from the training one\n",
    "testing_data = {\n",
    "    task: [{\"<input>\": example[\"c\"], \"<label>\": example[\"a\"]} \n",
    "           for examples in testing_examples.values() \n",
    "           for example in examples]\n",
    "    for task, testing_examples in task2testing_data.items()\n",
    "}\n",
    "testing_templates = {\n",
    "    task: [\n",
    "        f\"<input> {example[1]} <label>\" \n",
    "        for example in examples\n",
    "    ] for task, examples in task2testing_data.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(biclfs_data_dir / \"testing_data.pkl\", \"wb\") as f:\n",
    "    pkl.dump(testing_data, f)\n",
    "with open(biclfs_data_dir / \"testing_templates.pkl\", \"wb\") as f:\n",
    "    pkl.dump(testing_templates, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(biclfs_data_dir / \"training_data.pkl\", \"rb\") as f:\n",
    "    training_data = pkl.load(f)\n",
    "with open(biclfs_data_dir / \"testing_data.pkl\", \"rb\") as f:\n",
    "    testing_data = pkl.load(f)\n",
    "with open(biclfs_data_dir / \"training_templates.pkl\", \"rb\") as f:\n",
    "    training_templates = pkl.load(f)\n",
    "with open(biclfs_data_dir / \"testing_templates.pkl\", \"rb\") as f:\n",
    "    testing_templates = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<input>': '* food : tea , sugar , macaroni , canned beef , wheat flour , condensed milk ; * hygiene : detergent , laundry soap ; * bedding : bed linen , blankets ; * clothing : warm jackets , trousers , suits , felt boots ( for both adults and children ) .',\n",
       " 'template': '<input> Are the people described in the text in need of food? <label>',\n",
       " '<label>': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_templated = {}\n",
    "assert training_data.keys() == training_templates.keys()\n",
    "for task in training_data:\n",
    "    training_data_templated[task] = [\n",
    "        {\n",
    "            \"<input>\": example[\"<input>\"],\n",
    "            \"template\": template, # Might need to remove the period at the end\n",
    "            \"<label>\": example[\"<label>\"]\n",
    "        }\n",
    "        for example, template in zip(training_data[task], training_templates[task])\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_templated = {}\n",
    "assert testing_data.keys() == testing_templates.keys()\n",
    "for task in testing_data:\n",
    "    testing_data_templated[task] = [\n",
    "        {\n",
    "            \"<input>\": example[\"<input>\"],\n",
    "            \"template\": template, # Might need to remove the period at the end\n",
    "            \"<label>\": example[\"<label>\"]\n",
    "        }\n",
    "        for example, template in zip(testing_data[task], testing_templates[task])\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(biclfs_data_dir / \"training_data_templated.pkl\", \"wb\") as f:\n",
    "    pkl.dump(training_data_templated, f)\n",
    "with open(biclfs_data_dir / \"testing_data_templated.pkl\", \"wb\") as f:\n",
    "    pkl.dump(testing_data_templated, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ict",
   "language": "python",
   "name": "ict"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e7bc4b8e8cada99142c06b9ed43232f81e5e8caa43badd4883e0b628a3d44a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
